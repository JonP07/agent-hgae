+ ENGINE=vllm
+ export VLLM_ATTENTION_BACKEND=XFORMERS
+ VLLM_ATTENTION_BACKEND=XFORMERS
+ num_cpus_per_env_worker=0.1
+ train_data_size=4
+ val_data_size=4
+ group_size=4
+ python3 -m examples.data_preprocess.prepare --mode text --train_data_size 4 --val_data_size 4
num_proc must be <= 4. Reducing num_proc to 4 for dataset of size 4.
WARNING:2025-12-01 20:28:24,141:num_proc must be <= 4. Reducing num_proc to 4 for dataset of size 4.
num_proc must be <= 4. Reducing num_proc to 4 for dataset of size 4.
WARNING:2025-12-01 20:28:24,159:num_proc must be <= 4. Reducing num_proc to 4 for dataset of size 4.
processing data for mode: text
Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1237.99ba/s]
Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2814.97ba/s]
Exception ignored in: <function ResourceTracker.__del__ at 0x7f707d040900>
Traceback (most recent call last):
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 80, in __del__
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 89, in _stop
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 102, in _stop_locked
AttributeError: '_thread.RLock' object has no attribute '_recursion_count'
+ python3 -m verl.trainer.main_ppo algorithm.adv_estimator=grpo data.train_files=/users/3/peng0504/data/verl-agent/text/train.parquet data.val_files=/users/3/peng0504/data/verl-agent/text/test.parquet data.train_batch_size=4 data.val_batch_size=4 data.max_prompt_length=2048 data.max_response_length=512 data.filter_overlong_prompts=True data.truncation=error data.return_raw_chat=True actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct actor_rollout_ref.actor.optim.lr=1e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=4 actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=2 actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0.01 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=8 actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.6 actor_rollout_ref.rollout.enable_chunked_prefill=False actor_rollout_ref.rollout.enforce_eager=False actor_rollout_ref.rollout.free_cache_engine=False actor_rollout_ref.rollout.val_kwargs.temperature=0.4 actor_rollout_ref.rollout.val_kwargs.do_sample=True actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=2 actor_rollout_ref.ref.fsdp_config.param_offload=True actor_rollout_ref.actor.use_invalid_action_penalty=True actor_rollout_ref.actor.invalid_action_penalty_coef=0.1 algorithm.use_kl_in_reward=False env.env_name=alfworld/AlfredTWEnv env.seed=0 env.max_steps=50 env.rollout.n=4 env.resources_per_worker.num_cpus=0.1 trainer.critic_warmup=0 'trainer.logger=[console,wandb]' trainer.project_name=verl_agent_alfworld trainer.experiment_name=grpo_qwen2.5_0.5b trainer.n_gpus_per_node=1 trainer.nnodes=1 trainer.save_freq=-1 trainer.test_freq=5 trainer.total_epochs=150 trainer.val_before_train=True
2025-12-01 20:28:42,136	INFO worker.py:1942 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[36m(TaskRunner pid=1353405)[0m   0%|          | 0/8810 [00:00<?, ?it/s]
[36m(TaskRunner pid=1353405)[0m   1%|          | 56/8810 [00:00<00:15, 551.38it/s]
[36m(TaskRunner pid=1353405)[0m   1%|â–         | 129/8810 [00:00<00:13, 654.88it/s]
[36m(TaskRunner pid=1353405)[0m   2%|â–         | 212/8810 [00:00<00:11, 728.04it/s]
[36m(TaskRunner pid=1353405)[0m   3%|â–Ž         | 300/8810 [00:00<00:10, 785.97it/s]
[36m(TaskRunner pid=1353405)[0m   4%|â–         | 384/8810 [00:00<00:10, 793.34it/s]
[36m(TaskRunner pid=1353405)[0m   5%|â–Œ         | 464/8810 [00:00<00:10, 769.28it/s]
[36m(TaskRunner pid=1353405)[0m   6%|â–Œ         | 542/8810 [00:00<00:11, 726.25it/s]
[36m(TaskRunner pid=1353405)[0m   7%|â–‹         | 616/8810 [00:00<00:11, 720.04it/s]
[36m(TaskRunner pid=1353405)[0m   8%|â–Š         | 689/8810 [00:00<00:11, 683.99it/s]
[36m(TaskRunner pid=1353405)[0m   9%|â–‰         | 784/8810 [00:01<00:10, 758.95it/s]
[36m(TaskRunner pid=1353405)[0m  10%|â–‰         | 874/8810 [00:01<00:09, 799.06it/s]
[36m(TaskRunner pid=1353405)[0m  11%|â–ˆ         | 961/8810 [00:01<00:09, 815.78it/s]
[36m(TaskRunner pid=1353405)[0m  12%|â–ˆâ–        | 1044/8810 [00:01<00:16, 465.30it/s]
[36m(TaskRunner pid=1353405)[0m  13%|â–ˆâ–Ž        | 1109/8810 [00:01<00:16, 473.78it/s]
[36m(TaskRunner pid=1353405)[0m  13%|â–ˆâ–Ž        | 1171/8810 [00:01<00:15, 503.16it/s]
[36m(TaskRunner pid=1353405)[0m  14%|â–ˆâ–        | 1232/8810 [00:01<00:14, 520.80it/s]
[36m(TaskRunner pid=1353405)[0m  15%|â–ˆâ–        | 1292/8810 [00:02<00:14, 523.63it/s]
[36m(TaskRunner pid=1353405)[0m  15%|â–ˆâ–Œ        | 1350/8810 [00:02<00:14, 529.43it/s]
[36m(TaskRunner pid=1353405)[0m  16%|â–ˆâ–Œ        | 1409/8810 [00:02<00:13, 544.31it/s]
[36m(TaskRunner pid=1353405)[0m  17%|â–ˆâ–‹        | 1467/8810 [00:02<00:14, 505.64it/s]
[36m(TaskRunner pid=1353405)[0m  17%|â–ˆâ–‹        | 1533/8810 [00:02<00:13, 544.21it/s]
[36m(TaskRunner pid=1353405)[0m  18%|â–ˆâ–Š        | 1590/8810 [00:02<00:13, 526.75it/s]
[36m(TaskRunner pid=1353405)[0m  19%|â–ˆâ–Š        | 1646/8810 [00:02<00:13, 528.75it/s]
[36m(TaskRunner pid=1353405)[0m  19%|â–ˆâ–‰        | 1700/8810 [00:02<00:14, 485.57it/s]
[36m(TaskRunner pid=1353405)[0m  20%|â–ˆâ–‰        | 1757/8810 [00:02<00:13, 505.83it/s]
[36m(TaskRunner pid=1353405)[0m  21%|â–ˆâ–ˆ        | 1809/8810 [00:03<00:14, 494.27it/s]
[36m(TaskRunner pid=1353405)[0m  21%|â–ˆâ–ˆâ–       | 1894/8810 [00:03<00:11, 585.96it/s]
[36m(TaskRunner pid=1353405)[0m  22%|â–ˆâ–ˆâ–       | 1962/8810 [00:03<00:11, 611.42it/s]
[36m(TaskRunner pid=1353405)[0m  23%|â–ˆâ–ˆâ–Ž       | 2028/8810 [00:03<00:10, 618.56it/s]
[36m(TaskRunner pid=1353405)[0m  24%|â–ˆâ–ˆâ–       | 2094/8810 [00:03<00:10, 628.61it/s] 25%|â–ˆâ–ˆâ–       | 2175/8810 [00:03<00:09, 678.68it/s]
[36m(TaskRunner pid=1353405)[0m  25%|â–ˆâ–ˆâ–Œ       | 2244/8810 [00:03<00:10, 656.49it/s]
[36m(TaskRunner pid=1353405)[0m  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 3688/8810 [00:03<00:01, 4602.46it/s]
[36m(TaskRunner pid=1353405)[0m  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4166/8810 [00:04<00:03, 1454.31it/s]
[36m(TaskRunner pid=1353405)[0m  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4517/8810 [00:05<00:04, 1002.16it/s]
[36m(TaskRunner pid=1353405)[0m  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4778/8810 [00:05<00:04, 895.87it/s] 
[36m(TaskRunner pid=1353405)[0m  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4980/8810 [00:06<00:05, 739.47it/s]
[36m(TaskRunner pid=1353405)[0m  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5134/8810 [00:06<00:05, 720.00it/s]
[36m(TaskRunner pid=1353405)[0m  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5261/8810 [00:06<00:04, 773.86it/s]
[36m(TaskRunner pid=1353405)[0m  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 5388/8810 [00:06<00:04, 699.30it/s]
[36m(TaskRunner pid=1353405)[0m  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5538/8810 [00:06<00:04, 801.46it/s]
[36m(TaskRunner pid=1353405)[0m  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5655/8810 [00:07<00:04, 689.92it/s]
[36m(TaskRunner pid=1353405)[0m  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5751/8810 [00:07<00:05, 560.80it/s]
[36m(TaskRunner pid=1353405)[0m  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5828/8810 [00:07<00:05, 562.98it/s]
[36m(TaskRunner pid=1353405)[0m  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5899/8810 [00:07<00:05, 545.36it/s]
[36m(TaskRunner pid=1353405)[0m  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6007/8810 [00:07<00:04, 636.52it/s]
[36m(TaskRunner pid=1353405)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6123/8810 [00:08<00:03, 740.24it/s]
[36m(TaskRunner pid=1353405)[0m  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 6211/8810 [00:08<00:03, 677.44it/s]
[36m(TaskRunner pid=1353405)[0m  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 6483/8810 [00:08<00:02, 1123.40it/s]
[36m(TaskRunner pid=1353405)[0m  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6619/8810 [00:08<00:02, 775.99it/s] 
[36m(TaskRunner pid=1353405)[0m  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6727/8810 [00:09<00:03, 527.89it/s]
[36m(TaskRunner pid=1353405)[0m  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 6811/8810 [00:09<00:03, 530.51it/s]
[36m(TaskRunner pid=1353405)[0m  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6886/8810 [00:09<00:03, 530.70it/s]
[36m(TaskRunner pid=1353405)[0m  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6955/8810 [00:09<00:03, 535.59it/s]
[36m(TaskRunner pid=1353405)[0m  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 7155/8810 [00:09<00:02, 817.18it/s]
[36m(TaskRunner pid=1353405)[0m  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 7260/8810 [00:09<00:01, 862.75it/s]
[36m(TaskRunner pid=1353405)[0m  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 7406/8810 [00:09<00:01, 997.47it/s]
[36m(TaskRunner pid=1353405)[0m  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7522/8810 [00:09<00:01, 894.45it/s]
[36m(TaskRunner pid=1353405)[0m  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7624/8810 [00:10<00:01, 802.44it/s]
[36m(TaskRunner pid=1353405)[0m  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7714/8810 [00:10<00:01, 744.74it/s]
[36m(TaskRunner pid=1353405)[0m  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7796/8810 [00:10<00:01, 680.50it/s]
[36m(TaskRunner pid=1353405)[0m  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7870/8810 [00:10<00:01, 492.04it/s]
[36m(TaskRunner pid=1353405)[0m  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7929/8810 [00:10<00:01, 501.27it/s]
[36m(TaskRunner pid=1353405)[0m  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7987/8810 [00:10<00:01, 501.51it/s]
[36m(TaskRunner pid=1353405)[0m  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 8043/8810 [00:10<00:01, 484.66it/s]
[36m(TaskRunner pid=1353405)[0m  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 8095/8810 [00:11<00:01, 477.92it/s]
[36m(TaskRunner pid=1353405)[0m  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 8149/8810 [00:11<00:01, 490.43it/s]
[36m(TaskRunner pid=1353405)[0m  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 8213/8810 [00:11<00:01, 527.77it/s]
[36m(TaskRunner pid=1353405)[0m  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 8284/8810 [00:11<00:00, 573.41it/s]
[36m(TaskRunner pid=1353405)[0m  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 8344/8810 [00:11<00:00, 562.96it/s]
[36m(TaskRunner pid=1353405)[0m  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 8434/8810 [00:11<00:00, 650.40it/s]
[36m(TaskRunner pid=1353405)[0m  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 8501/8810 [00:11<00:00, 601.94it/s]
[36m(TaskRunner pid=1353405)[0m  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 8563/8810 [00:11<00:00, 567.04it/s]
[36m(TaskRunner pid=1353405)[0m  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8622/8810 [00:11<00:00, 565.12it/s]
[36m(TaskRunner pid=1353405)[0m  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8680/8810 [00:12<00:00, 549.41it/s]
[36m(TaskRunner pid=1353405)[0m  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8736/8810 [00:12<00:00, 550.79it/s]
[36m(TaskRunner pid=1353405)[0m 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8799/8810 [00:12<00:00, 572.27it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8810/8810 [00:12<00:00, 714.83it/s]
[36m(TaskRunner pid=1353405)[0m   0%|          | 0/494 [00:00<?, ?it/s]
[36m(TaskRunner pid=1353405)[0m  22%|â–ˆâ–ˆâ–       | 107/494 [00:00<00:00, 1062.48it/s]
[36m(TaskRunner pid=1353405)[0m  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 274/494 [00:00<00:00, 1415.53it/s]
[36m(TaskRunner pid=1353405)[0m  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/494 [00:00<00:00, 1246.99it/s]
[36m(TaskRunner pid=1353405)[0m 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 494/494 [00:00<00:00, 1138.91it/s]
[36m(TaskRunner pid=1353405)[0m Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 4 examples [00:00, 176.40 examples/s]
[36m(TaskRunner pid=1353405)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1353405)[0m WARNING:2025-12-01 20:29:26,536:Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1353405)[0m Filtering prompts longer than 2048 tokens (num_proc=1):   0%|          | 0/4 [00:00<?, ? examples/s]
[36m(TaskRunner pid=1353405)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.96 examples/s]
[36m(TaskRunner pid=1353405)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.57 examples/s]
[36m(TaskRunner pid=1353405)[0m Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 4 examples [00:00, 452.51 examples/s]
[36m(TaskRunner pid=1353405)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1353405)[0m WARNING:2025-12-01 20:29:27,387:Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=1353405)[0m Filtering prompts longer than 2048 tokens (num_proc=1):   0%|          | 0/4 [00:00<?, ? examples/s]
[36m(TaskRunner pid=1353405)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.38 examples/s]
[36m(TaskRunner pid=1353405)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.77 examples/s]
[36m(TaskRunner pid=1353405)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=1353405)[0m WARNING:2025-12-01 20:29:30,055:Waiting for register center actor 7lRN7M_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=1360126)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:444: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(WorkerDict pid=1360126)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:444: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:   3%|â–Ž         | 1/35 [00:00<00:19,  1.73it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:   6%|â–Œ         | 2/35 [00:00<00:14,  2.22it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:   9%|â–Š         | 3/35 [00:01<00:13,  2.42it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  11%|â–ˆâ–        | 4/35 [00:01<00:12,  2.53it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  14%|â–ˆâ–        | 5/35 [00:02<00:11,  2.61it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  17%|â–ˆâ–‹        | 6/35 [00:02<00:11,  2.61it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  20%|â–ˆâ–ˆ        | 7/35 [00:02<00:10,  2.61it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  23%|â–ˆâ–ˆâ–Ž       | 8/35 [00:03<00:10,  2.63it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:03<00:09,  2.64it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  29%|â–ˆâ–ˆâ–Š       | 10/35 [00:03<00:09,  2.65it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [00:04<00:08,  2.68it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:04<00:08,  2.70it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:05<00:08,  2.74it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [00:05<00:07,  2.70it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [00:05<00:07,  2.71it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 16/35 [00:06<00:06,  2.73it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 17/35 [00:06<00:06,  2.72it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:06<00:06,  2.73it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [00:07<00:05,  2.73it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 20/35 [00:07<00:05,  2.73it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:07<00:05,  2.74it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 22/35 [00:08<00:04,  2.73it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [00:08<00:04,  2.73it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:09<00:04,  2.52it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [00:09<00:04,  2.44it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [00:10<00:03,  2.41it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:10<00:03,  2.42it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:10<00:02,  2.38it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 29/35 [00:11<00:02,  2.23it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:11<00:02,  2.29it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:12<00:01,  2.14it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [00:12<00:01,  2.04it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:13<00:01,  1.91it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [00:14<00:00,  1.78it/s]
[36m(WorkerDict pid=1360126)[0m Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:14<00:00,  1.63it/s]Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:14<00:00,  2.36it/s]
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(TaskRunner pid=1353405)[0m wandb: Currently logged in as: peng0504 (mhong-university-of-minnesota) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(TaskRunner pid=1353405)[0m wandb: setting up run hnhpcwq2
[36m(TaskRunner pid=1353405)[0m wandb: Tracking run with wandb version 0.23.0
[36m(TaskRunner pid=1353405)[0m wandb: Run data is saved locally in /projects/standard/mhong/peng0504/wandb/run-20251201_203043-hnhpcwq2
[36m(TaskRunner pid=1353405)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(TaskRunner pid=1353405)[0m wandb: Syncing run grpo_qwen2.5_0.5b
[36m(TaskRunner pid=1353405)[0m wandb: â­ï¸ View project at https://wandb.ai/mhong-university-of-minnesota/verl_agent_alfworld
[36m(TaskRunner pid=1353405)[0m wandb: ðŸš€ View run at https://wandb.ai/mhong-university-of-minnesota/verl_agent_alfworld/runs/hnhpcwq2
[36m(TaskRunner pid=1353405)[0m wandb: Detected [openai] in use.
[36m(TaskRunner pid=1353405)[0m wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[36m(TaskRunner pid=1353405)[0m wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:773: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:711: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(TaskRunner pid=1353405)[0m Training Progress:   0%|          | 0/150 [00:00<?, ?it/s]
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:773: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:711: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:773: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(WorkerDict pid=1360126)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:711: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.
[36m(WorkerDict pid=1360126)[0m   warnings.warn(
[36m(TaskRunner pid=1353405)[0m {'actor_rollout_ref': {'actor': {'checkpoint': {'contents': ['model',
[36m(TaskRunner pid=1353405)[0m                                                              'optimizer',
[36m(TaskRunner pid=1353405)[0m                                                              'extra']},
[36m(TaskRunner pid=1353405)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=1353405)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=1353405)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=1353405)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=1353405)[0m                                  'entropy_coeff': 0.001,
[36m(TaskRunner pid=1353405)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(TaskRunner pid=1353405)[0m                                                  'offload_policy': False,
[36m(TaskRunner pid=1353405)[0m                                                  'optimizer_offload': False,
[36m(TaskRunner pid=1353405)[0m                                                  'param_offload': False,
[36m(TaskRunner pid=1353405)[0m                                                  'reshard_after_forward': True,
[36m(TaskRunner pid=1353405)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1353405)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=1353405)[0m                                  'invalid_action_penalty_coef': 0.1,
[36m(TaskRunner pid=1353405)[0m                                  'kl_loss_coef': 0.01,
[36m(TaskRunner pid=1353405)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=1353405)[0m                                  'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=1353405)[0m                                  'optim': {'lr': 1e-06,
[36m(TaskRunner pid=1353405)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=1353405)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1353405)[0m                                            'min_lr_ratio': 0.0,
[36m(TaskRunner pid=1353405)[0m                                            'num_cycles': 0.5,
[36m(TaskRunner pid=1353405)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=1353405)[0m                                            'warmup_style': 'constant',
[36m(TaskRunner pid=1353405)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=1353405)[0m                                  'policy_loss': {'loss_mode': 'vanilla'},
[36m(TaskRunner pid=1353405)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=1353405)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1353405)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1353405)[0m                                  'ppo_micro_batch_size_per_gpu': 2,
[36m(TaskRunner pid=1353405)[0m                                  'ppo_mini_batch_size': 4,
[36m(TaskRunner pid=1353405)[0m                                  'shuffle': False,
[36m(TaskRunner pid=1353405)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=1353405)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1353405)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=1353405)[0m                                  'use_invalid_action_penalty': True,
[36m(TaskRunner pid=1353405)[0m                                  'use_kl_loss': True,
[36m(TaskRunner pid=1353405)[0m                                  'use_torch_compile': True},
[36m(TaskRunner pid=1353405)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=1353405)[0m                        'model': {'enable_activation_offload': False,
[36m(TaskRunner pid=1353405)[0m                                  'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1353405)[0m                                  'external_lib': None,
[36m(TaskRunner pid=1353405)[0m                                  'lora_alpha': 16,
[36m(TaskRunner pid=1353405)[0m                                  'lora_rank': 0,
[36m(TaskRunner pid=1353405)[0m                                  'override_config': {},
[36m(TaskRunner pid=1353405)[0m                                  'path': 'Qwen/Qwen2.5-0.5B-Instruct',
[36m(TaskRunner pid=1353405)[0m                                  'target_modules': 'all-linear',
[36m(TaskRunner pid=1353405)[0m                                  'trust_remote_code': False,
[36m(TaskRunner pid=1353405)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=1353405)[0m                                  'use_liger': False,
[36m(TaskRunner pid=1353405)[0m                                  'use_remove_padding': True,
[36m(TaskRunner pid=1353405)[0m                                  'use_shm': False},
[36m(TaskRunner pid=1353405)[0m                        'ref': {'fsdp_config': {'param_offload': True,
[36m(TaskRunner pid=1353405)[0m                                                'reshard_after_forward': True,
[36m(TaskRunner pid=1353405)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1353405)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1353405)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1353405)[0m                                'log_prob_micro_batch_size_per_gpu': 2,
[36m(TaskRunner pid=1353405)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1353405)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=1353405)[0m                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1353405)[0m                                'use_torch_compile': True},
[36m(TaskRunner pid=1353405)[0m                        'rollout': {'chat_scheduler': None,
[36m(TaskRunner pid=1353405)[0m                                    'disable_log_stats': True,
[36m(TaskRunner pid=1353405)[0m                                    'do_sample': True,
[36m(TaskRunner pid=1353405)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=1353405)[0m                                    'enable_chunked_prefill': False,
[36m(TaskRunner pid=1353405)[0m                                    'enforce_eager': False,
[36m(TaskRunner pid=1353405)[0m                                    'engine_kwargs': {'sglang': {'attention_backend': None},
[36m(TaskRunner pid=1353405)[0m                                                      'vllm': {'swap_space': None}},
[36m(TaskRunner pid=1353405)[0m                                    'free_cache_engine': False,
[36m(TaskRunner pid=1353405)[0m                                    'gpu_memory_utilization': 0.6,
[36m(TaskRunner pid=1353405)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=1353405)[0m                                    'layered_summon': False,
[36m(TaskRunner pid=1353405)[0m                                    'load_format': 'dummy_dtensor',
[36m(TaskRunner pid=1353405)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1353405)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1353405)[0m                                    'log_prob_micro_batch_size_per_gpu': 8,
[36m(TaskRunner pid=1353405)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1353405)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=1353405)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=1353405)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=1353405)[0m                                    'mode': 'sync',
[36m(TaskRunner pid=1353405)[0m                                    'multi_turn': {'enable': False,
[36m(TaskRunner pid=1353405)[0m                                                   'format': 'chatml',
[36m(TaskRunner pid=1353405)[0m                                                   'max_turns': None,
[36m(TaskRunner pid=1353405)[0m                                                   'tool_config_path': None},
[36m(TaskRunner pid=1353405)[0m                                    'n': 1,
[36m(TaskRunner pid=1353405)[0m                                    'name': 'vllm',
[36m(TaskRunner pid=1353405)[0m                                    'prompt_length': 2048,
[36m(TaskRunner pid=1353405)[0m                                    'response_length': 512,
[36m(TaskRunner pid=1353405)[0m                                    'temperature': 1.0,
[36m(TaskRunner pid=1353405)[0m                                    'tensor_model_parallel_size': 1,
[36m(TaskRunner pid=1353405)[0m                                    'top_k': -1,
[36m(TaskRunner pid=1353405)[0m                                    'top_p': 1,
[36m(TaskRunner pid=1353405)[0m                                    'use_fire_sampling': False,
[36m(TaskRunner pid=1353405)[0m                                    'val_kwargs': {'do_sample': True,
[36m(TaskRunner pid=1353405)[0m                                                   'n': 1,
[36m(TaskRunner pid=1353405)[0m                                                   'temperature': 0.4,
[36m(TaskRunner pid=1353405)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=1353405)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=1353405)[0m  'algorithm': {'adv_estimator': 'grpo',
[36m(TaskRunner pid=1353405)[0m                'filter_groups': {'enable': False, 'max_num_gen_batches': 10},
[36m(TaskRunner pid=1353405)[0m                'gamma': 1.0,
[36m(TaskRunner pid=1353405)[0m                'gigpo': {'enable_similarity': False,
[36m(TaskRunner pid=1353405)[0m                          'mode': 'mean_norm',
[36m(TaskRunner pid=1353405)[0m                          'similarity_thresh': 0.95,
[36m(TaskRunner pid=1353405)[0m                          'step_advantage_w': 1.0},
[36m(TaskRunner pid=1353405)[0m                'kl_ctrl': {'horizon': 10000,
[36m(TaskRunner pid=1353405)[0m                            'kl_coef': 0.001,
[36m(TaskRunner pid=1353405)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=1353405)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=1353405)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=1353405)[0m                'lam': 1.0,
[36m(TaskRunner pid=1353405)[0m                'norm_adv_by_std_in_grpo': True,
[36m(TaskRunner pid=1353405)[0m                'pf_ppo': {'reweight_method': 'pow', 'weight_pow': 2.0},
[36m(TaskRunner pid=1353405)[0m                'use_kl_in_reward': False,
[36m(TaskRunner pid=1353405)[0m                'use_pf_ppo': False},
[36m(TaskRunner pid=1353405)[0m  'critic': {'checkpoint': {'contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=1353405)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=1353405)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1353405)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=1353405)[0m             'forward_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1353405)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=1353405)[0m             'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=1353405)[0m             'model': {'enable_activation_offload': False,
[36m(TaskRunner pid=1353405)[0m                       'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1353405)[0m                       'external_lib': None,
[36m(TaskRunner pid=1353405)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(TaskRunner pid=1353405)[0m                                       'offload_policy': False,
[36m(TaskRunner pid=1353405)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=1353405)[0m                                       'param_offload': False,
[36m(TaskRunner pid=1353405)[0m                                       'reshard_after_forward': True,
[36m(TaskRunner pid=1353405)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1353405)[0m                       'lora_alpha': 16,
[36m(TaskRunner pid=1353405)[0m                       'lora_rank': 0,
[36m(TaskRunner pid=1353405)[0m                       'override_config': {},
[36m(TaskRunner pid=1353405)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(TaskRunner pid=1353405)[0m                       'target_modules': 'all-linear',
[36m(TaskRunner pid=1353405)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-0.5B-Instruct',
[36m(TaskRunner pid=1353405)[0m                       'trust_remote_code': False,
[36m(TaskRunner pid=1353405)[0m                       'use_remove_padding': False,
[36m(TaskRunner pid=1353405)[0m                       'use_shm': False},
[36m(TaskRunner pid=1353405)[0m             'optim': {'lr': 1e-05,
[36m(TaskRunner pid=1353405)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1353405)[0m                       'min_lr_ratio': None,
[36m(TaskRunner pid=1353405)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=1353405)[0m                       'warmup_style': 'constant',
[36m(TaskRunner pid=1353405)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=1353405)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=1353405)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1353405)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1353405)[0m             'ppo_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1353405)[0m             'ppo_mini_batch_size': 4,
[36m(TaskRunner pid=1353405)[0m             'rollout_n': 1,
[36m(TaskRunner pid=1353405)[0m             'shuffle': False,
[36m(TaskRunner pid=1353405)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=1353405)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1353405)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=1353405)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=1353405)[0m  'data': {'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=1353405)[0m           'filter_overlong_prompts': True,
[36m(TaskRunner pid=1353405)[0m           'filter_overlong_prompts_workers': 1,
[36m(TaskRunner pid=1353405)[0m           'image_key': 'images',
[36m(TaskRunner pid=1353405)[0m           'max_prompt_length': 2048,
[36m(TaskRunner pid=1353405)[0m           'max_response_length': 512,
[36m(TaskRunner pid=1353405)[0m           'prompt_key': 'prompt',
[36m(TaskRunner pid=1353405)[0m           'return_full_prompt': False,
[36m(TaskRunner pid=1353405)[0m           'return_raw_chat': True,
[36m(TaskRunner pid=1353405)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=1353405)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=1353405)[0m           'shuffle': True,
[36m(TaskRunner pid=1353405)[0m           'tokenizer': None,
[36m(TaskRunner pid=1353405)[0m           'train_batch_size': 4,
[36m(TaskRunner pid=1353405)[0m           'train_files': '/users/3/peng0504/data/verl-agent/text/train.parquet',
[36m(TaskRunner pid=1353405)[0m           'truncation': 'error',
[36m(TaskRunner pid=1353405)[0m           'trust_remote_code': False,
[36m(TaskRunner pid=1353405)[0m           'use_shm': False,
[36m(TaskRunner pid=1353405)[0m           'val_batch_size': 4,
[36m(TaskRunner pid=1353405)[0m           'val_files': '/users/3/peng0504/data/verl-agent/text/test.parquet',
[36m(TaskRunner pid=1353405)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=1353405)[0m  'env': {'alfworld': {'eval_dataset': 'eval_in_distribution'},
[36m(TaskRunner pid=1353405)[0m          'env_name': 'alfworld/AlfredTWEnv',
[36m(TaskRunner pid=1353405)[0m          'history_length': 2,
[36m(TaskRunner pid=1353405)[0m          'max_steps': 50,
[36m(TaskRunner pid=1353405)[0m          'resources_per_worker': {'num_cpus': 0.1, 'num_gpus': 0},
[36m(TaskRunner pid=1353405)[0m          'rollout': {'n': 4},
[36m(TaskRunner pid=1353405)[0m          'search': {'log_requests': False,
[36m(TaskRunner pid=1353405)[0m                     'search_url': 'http://127.0.0.1:8000/retrieve',
[36m(TaskRunner pid=1353405)[0m                     'timeout': 60,
[36m(TaskRunner pid=1353405)[0m                     'topk': 3},
[36m(TaskRunner pid=1353405)[0m          'seed': 0,
[36m(TaskRunner pid=1353405)[0m          'sokoban': {'dim_room': [6, 6],
[36m(TaskRunner pid=1353405)[0m                      'mode': 'tiny_rgb_array',
[36m(TaskRunner pid=1353405)[0m                      'num_boxes': 1,
[36m(TaskRunner pid=1353405)[0m                      'search_depth': 30},
[36m(TaskRunner pid=1353405)[0m          'webshop': {'human_goals': False, 'use_small': True}},
[36m(TaskRunner pid=1353405)[0m  'ray_init': {'num_cpus': None},
[36m(TaskRunner pid=1353405)[0m  'reward_model': {'enable': False,
[36m(TaskRunner pid=1353405)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1353405)[0m                   'launch_reward_fn_async': False,
[36m(TaskRunner pid=1353405)[0m                   'max_length': None,
[36m(TaskRunner pid=1353405)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=1353405)[0m                   'micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1353405)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=1353405)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(TaskRunner pid=1353405)[0m                                             'param_offload': False,
[36m(TaskRunner pid=1353405)[0m                                             'reshard_after_forward': True,
[36m(TaskRunner pid=1353405)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1353405)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-0.5B-Instruct',
[36m(TaskRunner pid=1353405)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(TaskRunner pid=1353405)[0m                             'trust_remote_code': False,
[36m(TaskRunner pid=1353405)[0m                             'use_fused_kernels': False,
[36m(TaskRunner pid=1353405)[0m                             'use_remove_padding': False,
[36m(TaskRunner pid=1353405)[0m                             'use_shm': False},
[36m(TaskRunner pid=1353405)[0m                   'reward_manager': 'episode',
[36m(TaskRunner pid=1353405)[0m                   'sandbox_fusion': {'max_concurrent': 64, 'url': None},
[36m(TaskRunner pid=1353405)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=1353405)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1353405)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=1353405)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=1353405)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=1353405)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=1353405)[0m              'default_local_dir': 'checkpoints/verl_agent_alfworld/grpo_qwen2.5_0.5b',
[36m(TaskRunner pid=1353405)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=1353405)[0m              'device': 'cuda',
[36m(TaskRunner pid=1353405)[0m              'experiment_name': 'grpo_qwen2.5_0.5b',
[36m(TaskRunner pid=1353405)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=1353405)[0m              'logger': ['console', 'wandb'],
[36m(TaskRunner pid=1353405)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=1353405)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=1353405)[0m              'n_gpus_per_node': 1,
[36m(TaskRunner pid=1353405)[0m              'nnodes': 1,
[36m(TaskRunner pid=1353405)[0m              'project_name': 'verl_agent_alfworld',
[36m(TaskRunner pid=1353405)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=1353405)[0m              'resume_from_path': None,
[36m(TaskRunner pid=1353405)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=1353405)[0m              'rollout_data_dir': None,
[36m(TaskRunner pid=1353405)[0m              'save_freq': -1,
[36m(TaskRunner pid=1353405)[0m              'test_freq': 5,
[36m(TaskRunner pid=1353405)[0m              'total_epochs': 150,
[36m(TaskRunner pid=1353405)[0m              'total_training_steps': None,
[36m(TaskRunner pid=1353405)[0m              'val_before_train': True,
[36m(TaskRunner pid=1353405)[0m              'val_only': False,
[36m(TaskRunner pid=1353405)[0m              'validation_data_dir': None}}
[36m(TaskRunner pid=1353405)[0m Initializing AlfredTWEnv...
[36m(TaskRunner pid=1353405)[0m Overall we have 3553 games in split=train
[36m(TaskRunner pid=1353405)[0m Training with 3553 games
[36m(TaskRunner pid=1353405)[0m use_expert = False
[36m(TaskRunner pid=1353405)[0m Initializing AlfredTWEnv...
[36m(TaskRunner pid=1353405)[0m Overall we have 140 games in split=eval_in_distribution
[36m(TaskRunner pid=1353405)[0m Evaluating with 140 games
[36m(TaskRunner pid=1353405)[0m use_expert = False
[36m(TaskRunner pid=1353405)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=1353405)[0m dataset len: 4
[36m(TaskRunner pid=1353405)[0m filter dataset len: 4
[36m(TaskRunner pid=1353405)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=1353405)[0m dataset len: 4
[36m(TaskRunner pid=1353405)[0m filter dataset len: 4
[36m(TaskRunner pid=1353405)[0m WARNING: val_batch_size is deprecated. Validation datasets are sent to inference engines as a whole batch, which will schedule the memory themselves.
[36m(TaskRunner pid=1353405)[0m [validate_config] All configuration checks passed successfully!
[36m(TaskRunner pid=1353405)[0m Size of train dataloader: 1, Size of val dataloader: 1
[36m(TaskRunner pid=1353405)[0m Total training steps: 150
[36m(TaskRunner pid=1353405)[0m colocated worker base class <class 'verl.single_controller.base.worker.Worker'>
[36m(WorkerDict pid=1360126)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=1360126)[0m   "architectures": [
[36m(WorkerDict pid=1360126)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=1360126)[0m   ],
[36m(WorkerDict pid=1360126)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=1360126)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=1360126)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=1360126)[0m   "hidden_size": 896,
[36m(WorkerDict pid=1360126)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=1360126)[0m   "intermediate_size": 4864,
[36m(WorkerDict pid=1360126)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=1360126)[0m   "max_window_layers": 21,
[36m(WorkerDict pid=1360126)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=1360126)[0m   "num_attention_heads": 14,
[36m(WorkerDict pid=1360126)[0m   "num_hidden_layers": 24,
[36m(WorkerDict pid=1360126)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=1360126)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=1360126)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=1360126)[0m   "rope_scaling": null,
[36m(WorkerDict pid=1360126)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=1360126)[0m   "sliding_window": 32768,
[36m(WorkerDict pid=1360126)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=1360126)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=1360126)[0m   "transformers_version": "4.51.1",
[36m(WorkerDict pid=1360126)[0m   "use_cache": true,
[36m(WorkerDict pid=1360126)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=1360126)[0m   "vocab_size": 151936
[36m(WorkerDict pid=1360126)[0m }
[36m(WorkerDict pid=1360126)[0m 
[36m(WorkerDict pid=1360126)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1360126)[0m Qwen2ForCausalLM contains 494.03M parameters
[36m(WorkerDict pid=1360126)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f75394f22a0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f75394f2160>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=1360126)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=1360126)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=1360126)[0m Actor use_fused_kernels=False
[36m(WorkerDict pid=1360126)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=1360126)[0m   "architectures": [
[36m(WorkerDict pid=1360126)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=1360126)[0m   ],
[36m(WorkerDict pid=1360126)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=1360126)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=1360126)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=1360126)[0m   "hidden_size": 896,
[36m(WorkerDict pid=1360126)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=1360126)[0m   "intermediate_size": 4864,
[36m(WorkerDict pid=1360126)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=1360126)[0m   "max_window_layers": 21,
[36m(WorkerDict pid=1360126)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=1360126)[0m   "num_attention_heads": 14,
[36m(WorkerDict pid=1360126)[0m   "num_hidden_layers": 24,
[36m(WorkerDict pid=1360126)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=1360126)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=1360126)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=1360126)[0m   "rope_scaling": null,
[36m(WorkerDict pid=1360126)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=1360126)[0m   "sliding_window": 32768,
[36m(WorkerDict pid=1360126)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=1360126)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=1360126)[0m   "transformers_version": "4.51.1",
[36m(WorkerDict pid=1360126)[0m   "use_cache": true,
[36m(WorkerDict pid=1360126)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=1360126)[0m   "vocab_size": 151936
[36m(WorkerDict pid=1360126)[0m }
[36m(WorkerDict pid=1360126)[0m 
[36m(WorkerDict pid=1360126)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=1360126)[0m Qwen2ForCausalLM contains 494.03M parameters
[36m(WorkerDict pid=1360126)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f75394f22a0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f75394f2160>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=1360126)[0m Total steps: 150, num_warmup_steps: 0
[36m(WorkerDict pid=1360126)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=1360126)[0m Actor use_fused_kernels=False
[36m(WorkerDict pid=1360126)[0m WARNING 12-01 20:30:11 [arg_utils.py:1658] VLLM_ATTENTION_BACKEND=XFORMERS is not supported by the V1 Engine. Falling back to V0. We recommend to remove VLLM_ATTENTION_BACKEND=XFORMERS from your config in favor of the V1 Engine.
[36m(WorkerDict pid=1360126)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 512, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(TaskRunner pid=1353405)[0m Using LocalLogger is deprecated. The constructor API will change 
[36m(TaskRunner pid=1353405)[0m Checkpoint tracker file does not exist: %s /projects/standard/mhong/peng0504/checkpoints/verl_agent_alfworld/grpo_qwen2.5_0.5b/latest_checkpointed_iteration.txt
[36m(TaskRunner pid=1353405)[0m Training from scratch
[36m(TaskRunner pid=1353405)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True}
[36m(TaskRunner pid=1353405)[0m validation generation end
[36m(TaskRunner pid=1353405)[0m [text][prompt] <|im_start|>system
[36m(TaskRunner pid=1353405)[0m You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>
[36m(TaskRunner pid=1353405)[0m <|im_start|>user
[36m(TaskRunner pid=1353405)[0m 
[36m(TaskRunner pid=1353405)[0m You are an expert agent operating in the ALFRED Embodied Environment. Your task is to: put a clean butterknife in diningtable.
[36m(TaskRunner pid=1353405)[0m Prior to this step, you have already taken 3 step(s). Below are the most recent 2 observations and the corresponding actions you took: [Observation 2: 'Nothing happens.', Action 2: 'go to countertop 1']
[36m(TaskRunner pid=1353405)[0m [Observation 3: 'You arrive at countertop 1. On the countertop 1, you see a butterknife 2, a houseplant 2, a houseplant 1, a ladle 2, a pan 2, a pan 1, a peppershaker 2, a pot 2, a pot 1, a potato 2, a potato 1, a saltshaker 1, and a soapbottle 1.', Action 3: 'take butterknife 2 from countertop 1']
[36m(TaskRunner pid=1353405)[0m You are now at step 4 and your current observation is: You pick up the butterknife 2 from the countertop 1.
[36m(TaskRunner pid=1353405)[0m Your admissible actions of the current situation are: ['examine butterknife 2'
[36m(TaskRunner pid=1353405)[0m  'examine countertop 1'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 1'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 10'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 11'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 12'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 13'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 14'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 15'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 16'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 17'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 18'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 19'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 2'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 20'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 21'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 22'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 23'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 24'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 25'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 26'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 27'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 3'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 4'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 5'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 6'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 7'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 8'
[36m(TaskRunner pid=1353405)[0m  'go to cabinet 9'
[36m(TaskRunner pid=1353405)[0m  'go to coffeemachine 1'
[36m(TaskRunner pid=1353405)[0m  'go to countertop 2'
[36m(TaskRunner pid=1353405)[0m  'go to diningtable 1'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 1'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 10'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 11'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 12'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 2'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 3'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 4'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 5'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 6'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 7'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 8'
[36m(TaskRunner pid=1353405)[0m  'go to drawer 9'
[36m(TaskRunner pid=1353405)[0m  'go to fridge 1'
[36m(TaskRunner pid=1353405)[0m  'go to garbagecan 1'
[36m(TaskRunner pid=1353405)[0m  'go to microwave 1'
[36m(TaskRunner pid=1353405)[0m  'go to sinkbasin 1'
[36m(TaskRunner pid=1353405)[0m  'go to stoveburner 1'
[36m(TaskRunner pid=1353405)[0m  'go to stoveburner 2'
[36m(TaskRunner pid=1353405)[0m  'go to stoveburner 3'
[36m(TaskRunner pid=1353405)[0m  'go to stoveburner 4'
[36m(TaskRunner pid=1353405)[0m  'go to toaster 1'
[36m(TaskRunner pid=1353405)[0m  'inventory'
[36m(TaskRunner pid=1353405)[0m  'look'
[36m(TaskRunner pid=1353405)[0m  'move butterknife 2 to countertop 1'
[36m(TaskRunner pid=1353405)[0m  'slice potato 1 with butterknife 2'
[36m(TaskRunner pid=1353405)[0m  'slice potato 2 with butterknife 2'].
[36m(TaskRunner pid=1353405)[0m 
[36m(TaskRunner pid=1353405)[0m Now it's your turn to take an action.
[36m(TaskRunner pid=1353405)[0m You should first reason step-by-step about the current situation. This reasoning process MUST be enclosed within <think> </think> tags. 
[36m(TaskRunner pid=1353405)[0m Once you've finished your reasoning, you should choose an admissible action for current step and present it within <action> </action> tags.
[36m(TaskRunner pid=1353405)[0m <|im_end|>
[36m(TaskRunner pid=1353405)[0m <|im_start|>assistant
[36m(TaskRunner pid=1353405)[0m 
[36m(TaskRunner pid=1353405)[0m [text][response] <think>
[36m(TaskRunner pid=1353405)[0m To put a clean butterknife in the dining table, I need to:
[36m(TaskRunner pid=1353405)[0m 1. Go to countertop 1
[36m(TaskRunner pid=1353405)[0m 2. Take the butterknife 2 from countertop 1
[36m(TaskRunner pid=1353405)[0m 3. Go to diningtable 1
[36m(TaskRunner pid=1353405)[0m 4. Put the butterknife 2 in the dining table
[36m(TaskRunner pid=1353405)[0m </think>
[36m(TaskRunner pid=1353405)[0m 
[36m(TaskRunner pid=1353405)[0m <action>
[36m(TaskRunner pid=1353405)[0m go to countertop 1
[36m(TaskRunner pid=1353405)[0m go to diningtable 1
[36m(TaskRunner pid=1353405)[0m put the butterknife 2 in the dining table
[36m(TaskRunner pid=1353405)[0m </action><|im_end|>
[36m(TaskRunner pid=1353405)[0m [text][score] 0.0
[36m(TaskRunner pid=1353405)[0m ("Initial validation metrics: {'val/text/test_score': np.float64(0.0), "
[36m(TaskRunner pid=1353405)[0m  "'val/text/tool_call_count/mean': np.float64(0.0), "
[36m(TaskRunner pid=1353405)[0m  "'val/text/tool_call_count/max': np.float64(0.0), "
[36m(TaskRunner pid=1353405)[0m  "'val/text/tool_call_count/min': np.float64(0.0), 'val/success_rate': "
[36m(TaskRunner pid=1353405)[0m  "np.float64(0.0), 'val/pick_clean_then_place_in_recep_success_rate': "
[36m(TaskRunner pid=1353405)[0m  "np.float64(0.0), 'val/look_at_obj_in_light_success_rate': np.float64(0.0), "
[36m(TaskRunner pid=1353405)[0m  "'val/pick_and_place_success_rate': np.float64(0.0), "
[36m(TaskRunner pid=1353405)[0m  "'val/pick_heat_then_place_in_recep_success_rate': np.float64(0.0)}")
[36m(TaskRunner pid=1353405)[0m step:0 - val/text/test_score:0.000 - val/text/tool_call_count/mean:0.000 - val/text/tool_call_count/max:0.000 - val/text/tool_call_count/min:0.000 - val/success_rate:0.000 - val/pick_clean_then_place_in_recep_success_rate:0.000 - val/look_at_obj_in_light_success_rate:0.000 - val/pick_and_place_success_rate:0.000 - val/pick_heat_then_place_in_recep_success_rate:0.000
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff38deb1aaa75ceab73e6563ea01000000 Worker ID: c165daf086fc646f24420aba86d95e33993abb9717e9fb61ea8b29e7 Node ID: 44998afab74fe1a71911843911e98ec32730e19a43b2250f078671f3 Worker IP address: 10.31.104.74 Worker port: 43105 Worker PID: 1360126 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.
Error executing job with overrides: ['algorithm.adv_estimator=grpo', 'data.train_files=/users/3/peng0504/data/verl-agent/text/train.parquet', 'data.val_files=/users/3/peng0504/data/verl-agent/text/test.parquet', 'data.train_batch_size=4', 'data.val_batch_size=4', 'data.max_prompt_length=2048', 'data.max_response_length=512', 'data.filter_overlong_prompts=True', 'data.truncation=error', 'data.return_raw_chat=True', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-0.5B-Instruct', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=4', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=2', 'actor_rollout_ref.actor.use_kl_loss=True', 'actor_rollout_ref.actor.kl_loss_coef=0.01', 'actor_rollout_ref.actor.kl_loss_type=low_var_kl', 'actor_rollout_ref.model.enable_gradient_checkpointing=True', 'actor_rollout_ref.actor.fsdp_config.param_offload=False', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=False', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=8', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.6', 'actor_rollout_ref.rollout.enable_chunked_prefill=False', 'actor_rollout_ref.rollout.enforce_eager=False', 'actor_rollout_ref.rollout.free_cache_engine=False', 'actor_rollout_ref.rollout.val_kwargs.temperature=0.4', 'actor_rollout_ref.rollout.val_kwargs.do_sample=True', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=2', 'actor_rollout_ref.ref.fsdp_config.param_offload=True', 'actor_rollout_ref.actor.use_invalid_action_penalty=True', 'actor_rollout_ref.actor.invalid_action_penalty_coef=0.1', 'algorithm.use_kl_in_reward=False', 'env.env_name=alfworld/AlfredTWEnv', 'env.seed=0', 'env.max_steps=50', 'env.rollout.n=4', 'env.resources_per_worker.num_cpus=0.1', 'trainer.critic_warmup=0', 'trainer.logger=[console,wandb]', 'trainer.project_name=verl_agent_alfworld', 'trainer.experiment_name=grpo_qwen2.5_0.5b', 'trainer.n_gpus_per_node=1', 'trainer.nnodes=1', 'trainer.save_freq=-1', 'trainer.test_freq=5', 'trainer.total_epochs=150', 'trainer.val_before_train=True']
Traceback (most recent call last):
  File "/projects/standard/mhong/peng0504/options_agent/verl-agent/verl/trainer/main_ppo.py", line 29, in main
    run_ppo(config)
  File "/projects/standard/mhong/peng0504/options_agent/verl-agent/verl/trainer/main_ppo.py", line 41, in run_ppo
    ray.get(runner.run.remote(config))
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/ray/_private/worker.py", line 2882, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/ray/_private/worker.py", line 968, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ActorDiedError): [36mray::TaskRunner.run()[39m (pid=1353405, ip=10.31.104.74, actor_id=7bd391c021a1c20875d58ff401000000, repr=<main_ppo.TaskRunner object at 0x7f0bbf9380b0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/standard/mhong/peng0504/options_agent/verl-agent/verl/trainer/main_ppo.py", line 178, in run
    trainer.fit()
  File "/projects/standard/mhong/peng0504/options_agent/verl-agent/verl/trainer/ppo/ray_trainer.py", line 1082, in fit
    gen_batch_output = self.traj_collector.multi_turn_loop(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/standard/mhong/peng0504/options_agent/verl-agent/agent_system/multi_turn_rollout/rollout_loop.py", line 510, in multi_turn_loop
    self.vanilla_multi_turn_loop(
  File "/projects/standard/mhong/peng0504/options_agent/verl-agent/agent_system/multi_turn_rollout/rollout_loop.py", line 346, in vanilla_multi_turn_loop
    batch_output_padded = actor_rollout_wg.generate_sequences(batch_input_padded)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/projects/standard/mhong/peng0504/options_agent/verl-agent/verl/single_controller/ray/base.py", line 51, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.
	class_name: create_colocated_worker_cls.<locals>.WorkerDict
	actor_id: 38deb1aaa75ceab73e6563ea01000000
	pid: 1360126
	name: 7lRN7MWorkerDict_0:0
	namespace: b3408469-5fc3-48e4-a84b-9bfa3f5d5b1f
	ip: 10.31.104.74
The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Exception ignored in: <function ResourceTracker.__del__ at 0x7f90cb842f20>
Traceback (most recent call last):
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 80, in __del__
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 89, in _stop
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 102, in _stop_locked
AttributeError: '_thread.RLock' object has no attribute '_recursion_count'
