+ ENGINE=vllm
+ export VLLM_ATTENTION_BACKEND=XFORMERS
+ VLLM_ATTENTION_BACKEND=XFORMERS
+ export WANDB_ENTITY=mhong-university-of-minnesota
+ WANDB_ENTITY=mhong-university-of-minnesota
+ num_cpus_per_env_worker=0.1
+ train_data_size=128
+ val_data_size=128
+ python3 -m examples.data_preprocess.prepare --mode text --train_data_size 128 --val_data_size 128
processing data for mode: text
Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1534.69ba/s]
Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2417.47ba/s]
Exception ignored in: <function ResourceTracker.__del__ at 0x7fc89f370720>
Traceback (most recent call last):
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 80, in __del__
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 89, in _stop
  File "/users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/multiprocess/resource_tracker.py", line 102, in _stop_locked
AttributeError: '_thread.RLock' object has no attribute '_recursion_count'
+ python3 -m verl.trainer.main_ppo algorithm.adv_estimator=hgae data.train_files=/users/3/peng0504/data/verl-agent/text/train.parquet data.val_files=/users/3/peng0504/data/verl-agent/text/test.parquet data.train_batch_size=128 data.val_batch_size=128 data.max_prompt_length=2048 data.max_response_length=512 data.filter_overlong_prompts=True data.truncation=error data.return_raw_chat=True actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B-Instruct actor_rollout_ref.actor.optim.lr=1e-6 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.ppo_mini_batch_size=256 actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=16 actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0.01 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.model.enable_gradient_checkpointing=True actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32 actor_rollout_ref.rollout.tensor_model_parallel_size=2 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.5 actor_rollout_ref.rollout.enable_chunked_prefill=False actor_rollout_ref.rollout.enforce_eager=False actor_rollout_ref.rollout.free_cache_engine=False actor_rollout_ref.rollout.val_kwargs.temperature=0.4 actor_rollout_ref.rollout.val_kwargs.do_sample=True actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32 actor_rollout_ref.ref.fsdp_config.param_offload=True actor_rollout_ref.actor.use_invalid_action_penalty=True actor_rollout_ref.actor.invalid_action_penalty_coef=0.1 critic.optim.lr=1e-5 critic.model.use_remove_padding=True critic.model.path=Qwen/Qwen2.5-1.5B-Instruct critic.model.enable_gradient_checkpointing=True critic.ppo_micro_batch_size_per_gpu=16 critic.model.fsdp_config.param_offload=False critic.model.fsdp_config.optimizer_offload=False critic.use_two_heads_critic=True algorithm.use_kl_in_reward=False algorithm.hgae.norm_adv=True env.env_name=alfworld/AlfredTWEnvOptions env.seed=2 env.max_steps=50 env.resources_per_worker.num_cpus=0.1 reward_model.reward_manager=multi_turn 'trainer.logger=[console,wandb]' trainer.log_val_generations=10 trainer.project_name=verl_agent_alfworld trainer.experiment_name=hgae_qwen2.5_1.5b_seed_4_detached_norm_log trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.save_freq=-1 trainer.test_freq=5 trainer.total_epochs=150 trainer.val_before_train=True
2025-12-25 02:20:15,355	INFO worker.py:1942 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[36m(TaskRunner pid=3772955)[0m   0%|          | 0/8810 [00:00<?, ?it/s]
[36m(TaskRunner pid=3772955)[0m   2%|â–         | 145/8810 [00:00<00:06, 1441.19it/s]
[36m(TaskRunner pid=3772955)[0m   3%|â–Ž         | 290/8810 [00:00<00:06, 1403.06it/s]
[36m(TaskRunner pid=3772955)[0m   5%|â–Œ         | 482/8810 [00:00<00:05, 1628.40it/s]
[36m(TaskRunner pid=3772955)[0m   7%|â–‹         | 646/8810 [00:00<00:05, 1540.46it/s]
[36m(TaskRunner pid=3772955)[0m   9%|â–‰         | 833/8810 [00:00<00:04, 1653.21it/s]
[36m(TaskRunner pid=3772955)[0m  11%|â–ˆâ–        | 1000/8810 [00:00<00:07, 1035.57it/s]
[36m(TaskRunner pid=3772955)[0m  13%|â–ˆâ–Ž        | 1149/8810 [00:00<00:06, 1138.79it/s]
[36m(TaskRunner pid=3772955)[0m  15%|â–ˆâ–        | 1292/8810 [00:01<00:06, 1207.55it/s]
[36m(TaskRunner pid=3772955)[0m  16%|â–ˆâ–Œ        | 1431/8810 [00:01<00:05, 1254.63it/s]
[36m(TaskRunner pid=3772955)[0m  18%|â–ˆâ–Š        | 1574/8810 [00:01<00:05, 1300.36it/s]
[36m(TaskRunner pid=3772955)[0m  19%|â–ˆâ–‰        | 1716/8810 [00:01<00:05, 1331.42it/s]
[36m(TaskRunner pid=3772955)[0m  21%|â–ˆâ–ˆ        | 1857/8810 [00:01<00:05, 1351.72it/s]
[36m(TaskRunner pid=3772955)[0m  23%|â–ˆâ–ˆâ–Ž       | 1999/8810 [00:01<00:04, 1369.67it/s]
[36m(TaskRunner pid=3772955)[0m  24%|â–ˆâ–ˆâ–       | 2143/8810 [00:01<00:04, 1389.69it/s]
[36m(TaskRunner pid=3772955)[0m  26%|â–ˆâ–ˆâ–Œ       | 2302/8810 [00:01<00:04, 1444.16it/s]
[36m(TaskRunner pid=3772955)[0m  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3790/8810 [00:01<00:00, 5407.85it/s]
[36m(TaskRunner pid=3772955)[0m  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4340/8810 [00:02<00:01, 2603.37it/s]
[36m(TaskRunner pid=3772955)[0m  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 4761/8810 [00:02<00:01, 2082.96it/s]
[36m(TaskRunner pid=3772955)[0m  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5094/8810 [00:03<00:02, 1465.37it/s]
[36m(TaskRunner pid=3772955)[0m  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 5349/8810 [00:03<00:02, 1432.92it/s]
[36m(TaskRunner pid=3772955)[0m  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5567/8810 [00:03<00:02, 1461.23it/s]
[36m(TaskRunner pid=3772955)[0m  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 5767/8810 [00:03<00:03, 1011.18it/s]
[36m(TaskRunner pid=3772955)[0m  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 5921/8810 [00:04<00:02, 996.25it/s] 
[36m(TaskRunner pid=3772955)[0m  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6099/8810 [00:04<00:02, 1107.54it/s]
[36m(TaskRunner pid=3772955)[0m  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 6248/8810 [00:04<00:02, 1129.58it/s]
[36m(TaskRunner pid=3772955)[0m  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 6518/8810 [00:04<00:01, 1423.45it/s]
[36m(TaskRunner pid=3772955)[0m  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6697/8810 [00:04<00:02, 927.25it/s] 
[36m(TaskRunner pid=3772955)[0m  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 6836/8810 [00:04<00:02, 920.86it/s]
[36m(TaskRunner pid=3772955)[0m  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 6960/8810 [00:05<00:02, 918.85it/s]
[36m(TaskRunner pid=3772955)[0m  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 7188/8810 [00:05<00:01, 1174.10it/s]
[36m(TaskRunner pid=3772955)[0m  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 7402/8810 [00:05<00:01, 1378.26it/s]
[36m(TaskRunner pid=3772955)[0m  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 7570/8810 [00:05<00:00, 1319.72it/s]
[36m(TaskRunner pid=3772955)[0m  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7724/8810 [00:05<00:00, 1282.21it/s]
[36m(TaskRunner pid=3772955)[0m  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7867/8810 [00:05<00:01, 880.93it/s] 
[36m(TaskRunner pid=3772955)[0m  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7992/8810 [00:05<00:00, 947.23it/s]
[36m(TaskRunner pid=3772955)[0m  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 8109/8810 [00:06<00:00, 982.18it/s]
[36m(TaskRunner pid=3772955)[0m  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 8224/8810 [00:06<00:00, 990.62it/s]
[36m(TaskRunner pid=3772955)[0m  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 8346/8810 [00:06<00:00, 1043.82it/s]
[36m(TaskRunner pid=3772955)[0m  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 8492/8810 [00:06<00:00, 1147.70it/s]
[36m(TaskRunner pid=3772955)[0m  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 8616/8810 [00:06<00:00, 1150.41it/s]
[36m(TaskRunner pid=3772955)[0m  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 8738/8810 [00:06<00:00, 1163.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8810/8810 [00:06<00:00, 1337.42it/s]
[36m(TaskRunner pid=3772955)[0m   0%|          | 0/494 [00:00<?, ?it/s]
[36m(TaskRunner pid=3772955)[0m   2%|â–         | 11/494 [00:00<00:05, 92.24it/s]
[36m(TaskRunner pid=3772955)[0m   4%|â–         | 21/494 [00:00<00:07, 60.22it/s]
[36m(TaskRunner pid=3772955)[0m   6%|â–‹         | 32/494 [00:00<00:06, 76.35it/s]
[36m(TaskRunner pid=3772955)[0m   9%|â–‰         | 44/494 [00:00<00:05, 80.70it/s]
[36m(TaskRunner pid=3772955)[0m  13%|â–ˆâ–Ž        | 62/494 [00:00<00:04, 107.90it/s]
[36m(TaskRunner pid=3772955)[0m  15%|â–ˆâ–        | 74/494 [00:00<00:05, 81.59it/s] 
[36m(TaskRunner pid=3772955)[0m  17%|â–ˆâ–‹        | 84/494 [00:01<00:05, 70.85it/s]
[36m(TaskRunner pid=3772955)[0m  20%|â–ˆâ–ˆ        | 99/494 [00:01<00:04, 84.06it/s]
[36m(TaskRunner pid=3772955)[0m  22%|â–ˆâ–ˆâ–       | 111/494 [00:01<00:04, 91.20it/s]
[36m(TaskRunner pid=3772955)[0m  25%|â–ˆâ–ˆâ–       | 122/494 [00:01<00:08, 43.27it/s]
[36m(TaskRunner pid=3772955)[0m  26%|â–ˆâ–ˆâ–‹       | 130/494 [00:02<00:07, 48.23it/s]
[36m(TaskRunner pid=3772955)[0m  28%|â–ˆâ–ˆâ–Š       | 138/494 [00:02<00:07, 48.76it/s]
[36m(TaskRunner pid=3772955)[0m  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 220/494 [00:02<00:01, 182.67it/s]
[36m(TaskRunner pid=3772955)[0m  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 250/494 [00:02<00:01, 124.55it/s]
[36m(TaskRunner pid=3772955)[0m  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 273/494 [00:03<00:03, 59.91it/s] 
[36m(TaskRunner pid=3772955)[0m  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 290/494 [00:04<00:04, 50.57it/s]
[36m(TaskRunner pid=3772955)[0m  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 303/494 [00:04<00:03, 55.14it/s]
[36m(TaskRunner pid=3772955)[0m  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 317/494 [00:04<00:02, 60.09it/s]
[36m(TaskRunner pid=3772955)[0m  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 331/494 [00:04<00:02, 68.14it/s]
[36m(TaskRunner pid=3772955)[0m  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 343/494 [00:04<00:02, 58.35it/s]
[36m(TaskRunner pid=3772955)[0m  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 352/494 [00:05<00:03, 37.46it/s]
[36m(TaskRunner pid=3772955)[0m  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 362/494 [00:05<00:03, 41.42it/s]
[36m(TaskRunner pid=3772955)[0m  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 384/494 [00:05<00:01, 56.67it/s]
[36m(TaskRunner pid=3772955)[0m  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 392/494 [00:06<00:01, 52.76it/s]
[36m(TaskRunner pid=3772955)[0m  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/494 [00:06<00:01, 57.15it/s]
[36m(TaskRunner pid=3772955)[0m  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/494 [00:06<00:01, 68.33it/s]
[36m(TaskRunner pid=3772955)[0m  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 429/494 [00:06<00:00, 79.21it/s]
[36m(TaskRunner pid=3772955)[0m  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 439/494 [00:06<00:00, 68.92it/s]
[36m(TaskRunner pid=3772955)[0m  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 448/494 [00:06<00:00, 69.52it/s]
[36m(TaskRunner pid=3772955)[0m  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 456/494 [00:06<00:00, 67.64it/s]
[36m(TaskRunner pid=3772955)[0m  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/494 [00:07<00:00, 56.72it/s]
[36m(TaskRunner pid=3772955)[0m  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472/494 [00:07<00:00, 56.21it/s]
[36m(TaskRunner pid=3772955)[0m  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 479/494 [00:07<00:00, 58.77it/s]
[36m(TaskRunner pid=3772955)[0m  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 488/494 [00:07<00:00, 64.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 494/494 [00:07<00:00, 65.41it/s]
[36m(TaskRunner pid=3772955)[0m Generating train split: 0 examples [00:00, ? examples/s]
[36m(TaskRunner pid=3772955)[0m Generating train split: 128 examples [00:00, 1267.68 examples/s]
[36m(TaskRunner pid=3772955)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=3772955)[0m WARNING:2025-12-25 02:21:30,862:Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=3772955)[0m Filtering prompts longer than 2048 tokens (num_proc=1):   0%|          | 0/128 [00:00<?, ? examples/s]
[36m(TaskRunner pid=3772955)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:01<00:00, 90.01 examples/s]
[36m(TaskRunner pid=3772955)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:01<00:00, 73.29 examples/s]
[36m(TaskRunner pid=3772955)[0m Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 128 examples [00:00, 10506.90 examples/s]
[36m(TaskRunner pid=3772955)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=3772955)[0m WARNING:2025-12-25 02:21:33,070:Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(TaskRunner pid=3772955)[0m Filtering prompts longer than 2048 tokens (num_proc=1):   0%|          | 0/128 [00:00<?, ? examples/s]
[36m(TaskRunner pid=3772955)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:01<00:00, 80.41 examples/s]
[36m(TaskRunner pid=3772955)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:01<00:00, 66.22 examples/s]
[36m(TaskRunner pid=3772955)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=3772955)[0m WARNING:2025-12-25 02:21:54,289:Waiting for register center actor cGk71H_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=3802091)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=3802091)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=3802985)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=3802985)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=3802985)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=3802983)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3802091)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct and are newly initialized: ['score.bias', 'score.weight'][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3802091)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3802984)[0m Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]
[36m(WorkerDict pid=3802091)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=3802984)[0m Capturing CUDA graph shapes:   3%|â–Ž         | 1/35 [00:00<00:20,  1.67it/s]
[36m(WorkerDict pid=3802984)[0m Capturing CUDA graph shapes:   6%|â–Œ         | 2/35 [00:01<00:18,  1.79it/s]
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes:  17%|â–ˆâ–‹        | 6/35 [00:05<00:25,  1.13it/s][32m [repeated 14x across cluster][0m
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes:  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:10<00:19,  1.15it/s][32m [repeated 15x across cluster][0m
[36m(WorkerDict pid=3802984)[0m Capturing CUDA graph shapes:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 29/35 [00:16<00:03,  1.77it/s][32m [repeated 17x across cluster][0m
[36m(WorkerDict pid=3802984)[0m Capturing CUDA graph shapes:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [00:17<00:01,  1.79it/s]
[36m(WorkerDict pid=3802984)[0m Capturing CUDA graph shapes:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:18<00:01,  1.80it/s]
[36m(WorkerDict pid=3802984)[0m Capturing CUDA graph shapes:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [00:18<00:00,  1.80it/s]
[36m(WorkerDict pid=3802984)[0m Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:19<00:00,  1.74it/s]Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:19<00:00,  1.79it/s]
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [00:20<00:07,  1.21it/s][32m [repeated 9x across cluster][0m
[36m(WorkerDict pid=3802985)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3802985)[0m   warnings.warn(
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [00:25<00:02,  1.23it/s]
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:26<00:01,  1.21it/s]
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:24<00:03,  1.26it/s][32m [repeated 5x across cluster][0m
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [00:27<00:00,  1.20it/s]
[36m(WorkerDict pid=3802091)[0m Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:28<00:00,  1.16it/s]Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:28<00:00,  1.23it/s]
[36m(WorkerDict pid=3802983)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=3802983)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(TaskRunner pid=3772955)[0m wandb: Currently logged in as: peng0504 (mhong-university-of-minnesota) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(TaskRunner pid=3772955)[0m wandb: setting up run ql03wr04
[36m(TaskRunner pid=3772955)[0m wandb: Tracking run with wandb version 0.23.0
[36m(TaskRunner pid=3772955)[0m wandb: Run data is saved locally in /projects/standard/mhong/peng0504/HGAE-Agent/verl-agent/wandb/run-20251225_022340-ql03wr04
[36m(TaskRunner pid=3772955)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(TaskRunner pid=3772955)[0m wandb: Syncing run hgae_qwen2.5_1.5b_seed_4_detached_norm_log
[36m(TaskRunner pid=3772955)[0m wandb: â­ï¸ View project at https://wandb.ai/mhong-university-of-minnesota/verl_agent_alfworld
[36m(TaskRunner pid=3772955)[0m wandb: ðŸš€ View run at https://wandb.ai/mhong-university-of-minnesota/verl_agent_alfworld/runs/ql03wr04
[36m(TaskRunner pid=3772955)[0m wandb: Detected [openai] in use.
[36m(TaskRunner pid=3772955)[0m wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[36m(TaskRunner pid=3772955)[0m wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
[36m(TaskRunner pid=3772955)[0m Training Progress:   0%|          | 0/150 [00:00<?, ?it/s]
[36m(WorkerDict pid=3802091)[0m /users/3/peng0504/.conda/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=3802091)[0m   warnings.warn(
[36m(TaskRunner pid=3772955)[0m Training Progress:   1%|          | 1/150 [05:23<13:22:37, 323.20s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   1%|â–         | 2/150 [10:51<13:25:18, 326.48s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   2%|â–         | 3/150 [16:18<13:19:45, 326.43s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   3%|â–Ž         | 4/150 [21:38<13:08:44, 324.14s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   3%|â–Ž         | 5/150 [29:47<15:26:21, 383.32s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   4%|â–         | 6/150 [35:19<14:38:22, 365.99s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   5%|â–         | 7/150 [40:50<14:05:11, 354.63s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   5%|â–Œ         | 8/150 [46:17<13:38:35, 345.88s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   6%|â–Œ         | 9/150 [51:48<13:21:26, 341.04s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   7%|â–‹         | 10/150 [1:00:03<15:06:56, 388.69s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   7%|â–‹         | 11/150 [1:05:45<14:26:53, 374.19s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   8%|â–Š         | 12/150 [1:11:17<13:51:36, 361.57s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   9%|â–Š         | 13/150 [1:16:41<13:19:40, 350.23s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:   9%|â–‰         | 14/150 [1:22:09<12:58:41, 343.54s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  10%|â–ˆ         | 15/150 [1:30:21<14:33:02, 388.02s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  11%|â–ˆ         | 16/150 [1:36:04<13:56:33, 374.58s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  11%|â–ˆâ–        | 17/150 [1:41:40<13:24:42, 363.02s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  12%|â–ˆâ–        | 18/150 [1:47:20<13:03:06, 355.96s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  13%|â–ˆâ–Ž        | 19/150 [1:52:52<12:41:35, 348.82s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  13%|â–ˆâ–Ž        | 20/150 [2:00:36<13:51:05, 383.58s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  14%|â–ˆâ–        | 21/150 [2:05:58<13:04:45, 365.00s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  15%|â–ˆâ–        | 22/150 [2:11:23<12:33:17, 353.11s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  15%|â–ˆâ–Œ        | 23/150 [2:16:44<12:06:51, 343.40s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  16%|â–ˆâ–Œ        | 24/150 [2:22:03<11:45:32, 335.98s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  17%|â–ˆâ–‹        | 25/150 [2:30:01<13:09:04, 378.76s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  17%|â–ˆâ–‹        | 26/150 [2:35:15<12:22:08, 359.10s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  18%|â–ˆâ–Š        | 27/150 [2:40:54<12:04:15, 353.30s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  19%|â–ˆâ–Š        | 28/150 [2:46:24<11:43:54, 346.19s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  19%|â–ˆâ–‰        | 29/150 [2:52:28<11:49:01, 351.58s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  20%|â–ˆâ–ˆ        | 30/150 [3:05:17<15:53:29, 476.75s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  21%|â–ˆâ–ˆ        | 31/150 [3:13:22<15:50:22, 479.18s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  21%|â–ˆâ–ˆâ–       | 32/150 [3:21:06<15:33:31, 474.67s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  22%|â–ˆâ–ˆâ–       | 33/150 [3:28:02<14:51:28, 457.17s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 34/150 [3:35:37<14:42:41, 456.57s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  23%|â–ˆâ–ˆâ–Ž       | 35/150 [3:45:56<16:08:24, 505.26s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  24%|â–ˆâ–ˆâ–       | 36/150 [3:52:56<15:11:10, 479.57s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  25%|â–ˆâ–ˆâ–       | 37/150 [3:59:49<14:25:40, 459.65s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  25%|â–ˆâ–ˆâ–Œ       | 38/150 [4:06:09<13:33:04, 435.58s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  26%|â–ˆâ–ˆâ–Œ       | 39/150 [4:12:55<13:09:39, 426.84s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 40/150 [4:23:01<14:40:47, 480.43s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  27%|â–ˆâ–ˆâ–‹       | 41/150 [4:30:01<14:00:04, 462.43s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  28%|â–ˆâ–ˆâ–Š       | 42/150 [4:37:33<13:46:55, 459.40s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  29%|â–ˆâ–ˆâ–Š       | 43/150 [4:44:37<13:20:21, 448.80s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  29%|â–ˆâ–ˆâ–‰       | 44/150 [4:52:02<13:10:41, 447.56s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  30%|â–ˆâ–ˆâ–ˆ       | 45/150 [5:02:46<14:46:07, 506.35s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆ       | 46/150 [5:10:00<14:00:23, 484.84s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 47/150 [5:17:18<13:27:57, 470.66s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 48/150 [5:24:41<13:06:17, 462.53s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 49/150 [5:31:34<12:33:40, 447.73s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 50/150 [5:41:08<13:29:19, 485.60s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 51/150 [5:48:10<12:49:41, 466.48s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–      | 52/150 [5:55:18<12:23:02, 454.92s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 53/150 [6:02:12<11:55:30, 442.59s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 54/150 [6:09:19<11:40:46, 437.99s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 55/150 [6:20:01<13:10:09, 499.04s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 56/150 [6:27:02<12:25:10, 475.65s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 57/150 [6:34:19<11:59:09, 463.97s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 58/150 [6:41:32<11:37:27, 454.87s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 59/150 [6:48:46<11:20:17, 448.55s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 60/150 [7:00:09<12:58:17, 518.86s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 61/150 [7:07:19<12:10:00, 492.14s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 62/150 [7:14:15<11:28:26, 469.39s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 63/150 [7:20:47<10:46:48, 446.08s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 64/150 [7:27:22<10:17:29, 430.81s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 65/150 [7:36:33<11:01:18, 466.80s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/150 [7:42:42<10:12:39, 437.61s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/150 [7:48:32<9:29:00, 411.33s/it] 
[36m(TaskRunner pid=3772955)[0m Training Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 68/150 [7:54:37<9:02:52, 397.22s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 69/150 [8:00:55<8:48:41, 391.62s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 70/150 [8:09:37<9:34:12, 430.66s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 71/150 [8:15:38<8:59:27, 409.71s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 72/150 [8:21:48<8:37:16, 397.91s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 73/150 [8:28:16<8:26:55, 395.01s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 74/150 [8:35:01<8:24:06, 397.98s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 75/150 [8:45:05<9:34:47, 459.83s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 76/150 [8:52:11<9:14:27, 449.55s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 77/150 [8:59:13<8:56:59, 441.37s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 78/150 [9:06:13<8:41:48, 434.84s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 79/150 [9:13:34<8:36:38, 436.60s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 80/150 [9:25:04<9:58:15, 512.80s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 81/150 [9:32:16<9:21:42, 488.45s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/150 [9:39:10<8:48:20, 466.18s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 83/150 [9:46:13<8:26:03, 453.18s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 84/150 [9:52:48<7:59:21, 435.78s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 85/150 [10:03:32<8:59:53, 498.36s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 86/150 [10:10:14<8:20:39, 469.37s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 87/150 [10:17:22<7:59:37, 456.78s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 88/150 [10:24:29<7:42:56, 448.01s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 89/150 [10:31:48<7:32:43, 445.31s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 90/150 [10:44:04<8:52:31, 532.53s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 91/150 [10:51:18<8:14:38, 503.03s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 92/150 [10:58:41<7:48:38, 484.81s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 93/150 [11:06:01<7:28:00, 471.59s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 94/150 [11:13:16<7:09:49, 460.52s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 95/150 [11:26:00<8:25:39, 551.63s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 96/150 [11:33:28<7:48:27, 520.51s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 97/150 [11:40:42<7:16:42, 494.40s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 98/150 [11:47:43<6:49:30, 472.50s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 99/150 [11:55:09<6:34:50, 464.51s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 100/150 [12:07:50<7:41:07, 553.34s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 101/150 [12:15:15<7:05:30, 521.02s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 102/150 [12:22:29<6:35:57, 494.94s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 103/150 [12:29:34<6:11:08, 473.79s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 104/150 [12:36:03<5:43:50, 448.49s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 105/150 [12:47:10<6:25:31, 514.03s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 106/150 [12:53:42<5:50:10, 477.52s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 107/150 [13:00:38<5:28:53, 458.93s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 108/150 [13:07:24<5:10:14, 443.19s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 109/150 [13:14:09<4:55:00, 431.73s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 110/150 [13:25:50<5:41:37, 512.43s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 111/150 [13:32:51<5:15:09, 484.87s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 112/150 [13:39:49<4:54:27, 464.93s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 113/150 [13:46:33<4:35:21, 446.53s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 114/150 [13:52:54<4:16:14, 427.08s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 115/150 [14:03:02<4:40:42, 481.20s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 116/150 [14:09:05<4:12:36, 445.79s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 117/150 [14:15:00<3:50:07, 418.40s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 118/150 [14:20:40<3:30:36, 394.90s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 119/150 [14:26:28<3:16:46, 380.86s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 120/150 [14:34:52<3:29:00, 418.02s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 121/150 [14:40:30<3:10:24, 393.96s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 122/150 [14:46:16<2:57:04, 379.44s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 123/150 [14:51:54<2:45:11, 367.09s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 124/150 [14:57:38<2:36:03, 360.14s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 125/150 [15:05:40<2:45:18, 396.73s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 126/150 [15:11:07<2:30:21, 375.91s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 127/150 [15:15:44<2:12:40, 346.09s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 128/150 [15:20:28<2:00:02, 327.38s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 129/150 [15:24:59<1:48:44, 310.69s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 130/150 [15:32:27<1:57:16, 351.83s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 131/150 [15:37:48<1:48:29, 342.62s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 132/150 [15:43:15<1:41:23, 337.96s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 133/150 [15:48:38<1:34:28, 333.45s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 134/150 [15:54:29<1:30:18, 338.68s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 135/150 [16:04:23<1:43:48, 415.22s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 136/150 [16:10:12<1:32:13, 395.23s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 137/150 [16:16:15<1:23:33, 385.67s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 138/150 [16:22:15<1:15:37, 378.09s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 139/150 [16:28:19<1:08:31, 373.80s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 140/150 [16:38:08<1:13:02, 438.26s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 141/150 [16:44:05<1:02:05, 413.98s/it]
[36m(TaskRunner pid=3772955)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 142/150 [16:49:52<52:31, 393.96s/it]  
[36m(TaskRunner pid=3772955)[0m Training Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 143/150 [16:55:34<44:08, 378.30s/it]
*** SIGTERM received at time=1766712408 on cpu 70 ***
PC: @     0x7faa5658c628  (unknown)  pthread_cond_timedwait@@GLIBC_2.3.2
    @     0x7faa56590990  (unknown)  (unknown)
    @        0x100000000  (unknown)  (unknown)
[2025-12-25 19:26:48,549 E 3764384 3764384] logging.cc:474: *** SIGTERM received at time=1766712408 on cpu 70 ***
[2025-12-25 19:26:48,549 E 3764384 3764384] logging.cc:474: PC: @     0x7faa5658c628  (unknown)  pthread_cond_timedwait@@GLIBC_2.3.2
[2025-12-25 19:26:48,582 E 3764384 3764384] logging.cc:474:     @     0x7faa56590990  (unknown)  (unknown)
[2025-12-25 19:26:48,609 E 3764384 3764384] logging.cc:474:     @        0x100000000  (unknown)  (unknown)
